# 服务器
server.port=8888

#============== kafka ===================
# 代理地址：服务器+端口，可以多个用,隔开
spring.kafka.bootstrap-servers=127.0.0.1:9092
# 指定消息体 topic 主题
spring.kafka.topic.helloworld: testtopic
# 安全认证
spring.kafka.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.sasl.jaas.config='org.apache.kafka.common.security.scram.ScramLoginModule required username="visitor" password="hntl@2021";'
#=============== provider  =======================
# acks=0 ： 生产者在发送消息后立即返回，不等待服务器的响应结果。(完全不关心消息是否发送成功，允许消息丢失)
# acks=1 ： 只要集群的leader节点收到消息，生产者就会收到一个来自服务器的成功响应。(一般场景即可)
# acks=all或-1 ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。(不能容忍消息丢失)
spring.kafka.producer.acks=1
# 发生错误后，消息重发的次数
spring.kafka.producer.retries=0
# 当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算
spring.kafka.producer.batchSize=16384
# 设置生产者内存缓冲区的大小
spring.kafka.producer.bufferMemory=33554432
# 指定消息key和消息体的序列化方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=consumer-group-test
# 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：
# latest（默认值）在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）
# earliest ：在偏移量无效的情况下，消费者将从起始位置读取分区的记录
spring.kafka.consumer.auto-offset-reset=earliest
# 是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
spring.kafka.consumer.enable-auto-commit=false
# 自动提交的时间间隔，单位ms 在spring boot 2.X 版本中这里采用的是值的类型为Duration 需要符合特定的格式，如1S,1M,2H,5D
spring.kafka.consumer.auto-commit-interval=100
# 指定消息key和消息体的反序列化方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer